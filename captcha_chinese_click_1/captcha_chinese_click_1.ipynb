{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练中文点选验证码-类型1\n",
    "\n",
    "使用yolo11n模型进行目标检测\n",
    "\n",
    "使用vgg16模型训练孪生神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# 把当前工作目录添加到sys.path中\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "root = os.path.abspath(\"..\")\n",
    "os.makedirs(os.path.join(root, \"models\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集\n",
    "import my_datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset: Dataset = my_datasets.get_dataset(\"captcha_chinese_click_1\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据总共451张验证码图片，比较少，所以测试集比例选择了10%\n",
    "\n",
    "train_test_dataset = dataset.train_test_split(test_size=0.1, shuffle=True)\n",
    "train_dataset = train_test_dataset['train']\n",
    "test_dataset = train_test_dataset['test']\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集转换为yolo格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def toYolo(dataset: Dataset, output_dir):\n",
    "    # 设置输出目录的位置\n",
    "    images_dir = os.path.join(output_dir, \"images\")  # 图片保存目录\n",
    "    labels_dir = os.path.join(output_dir, \"labels\")  # 标签保存目录\n",
    "\n",
    "    # 确保输出目录及其子目录存在\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    for idx, data in enumerate(dataset):\n",
    "        image: Image = data['image']\n",
    "        objects: object = data['objects']\n",
    "        bbox: list[list[int]] = objects['bbox']\n",
    "        # categories: list[int] = objects['categories']\n",
    "\n",
    "        img_width, img_height = image.size\n",
    "\n",
    "        image_filename = str(idx) + '.jpg'\n",
    "        label_filename = str(idx) + '.txt'\n",
    "\n",
    "        image_filepath = os.path.join(images_dir, image_filename)\n",
    "        label_filepath = os.path.join(labels_dir, label_filename)\n",
    "\n",
    "        image.save(image_filepath)\n",
    "\n",
    "        with open(label_filepath, 'w') as f:\n",
    "            for idx, box in enumerate(bbox):\n",
    "                x_min, y_min, x_max, y_max = box\n",
    "                category = 0 # 默认类别为0\n",
    "                # category = categories[idx]\n",
    "\n",
    "                # 将边界框转换为YOLO格式：(class_id, x_center, y_center, width, height)\n",
    "                x_center = (x_min + x_max) / 2 / img_width\n",
    "                y_center = (y_min + y_max) / 2 / img_height\n",
    "                width = (x_max - x_min) / img_width\n",
    "                height = (y_max - y_min) / img_height\n",
    "\n",
    "                # 写入标签文件，格式为：class_id x_center y_center width height\n",
    "                f.write(f\"{category} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "\n",
    "root = os.path.abspath(\"..\")\n",
    "yolo_root = os.path.join(root, \"datasets/captcha_chinese_click_1/yolo\")\n",
    "toYolo(dataset=train_dataset, output_dir=os.path.join(yolo_root, \"train\"))\n",
    "toYolo(dataset=test_dataset, output_dir=os.path.join(yolo_root, \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练yolo11n模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "\n",
    "yolo11_model = YOLO(os.path.join(root, \"models\", \"yolo11n.pt\"))\n",
    "train_parms = {\n",
    "    \"train\": os.path.abspath(os.path.join(yolo_root, \"train\")),\n",
    "    \"val\": os.path.abspath(os.path.join(yolo_root, \"test\")),\n",
    "    \"nc\": 1,\n",
    "    \"names\": [\"text\"],\n",
    "}\n",
    "\n",
    "yaml.dump(train_parms, open(os.path.join(yolo_root, \"data.yaml\"), \"w\"))\n",
    "\n",
    "results = yolo11_model.train(\n",
    "    pretrained=os.path.join(root, \"models\", \"yolo11n.pt\"),\n",
    "    amp=False,  # 开启自动混合精度训练加速 需要在当前目录下载模型 明明有模型了还要下载 没搞明白为什么不能改目录\n",
    "    project=\"captcha_chinese_click_1\",\n",
    "    data=os.path.join(yolo_root, \"data.yaml\"),\n",
    "    epochs=100,\n",
    "    batch=16,\n",
    "    imgsz=384,\n",
    "    device=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导出yolo模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo11_model.export(\n",
    "    format='onnx',\n",
    "    # 动态batch_size\n",
    "    dynamic=True,\n",
    "    # 在模型内部开启非极大值抑制，减少后处理的计算量\n",
    "    nms=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 孪生神经网络(其实就是VGG16啦)\n",
    "\n",
    "简单说一下原理，其实就是 先提取图像的特征，展平出一维特征图，然后求两个特征图之间的欧式距离。\n",
    "\n",
    "每条训练数据有三个样本，分别为基样本，正向激励样本，反向激励样本\n",
    "\n",
    "基样本和正向激励样本是同一个文字，反向激励样本是另一个文字\n",
    "\n",
    "那么loss的规则就是，基样本和正向激励样本距离越大loss越大，基样本和反向激励样本距离越大loss越小\n",
    "\n",
    "详情请搜索Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        # 用了ImageNet上的预训练权重，所以输入的时候要进行标准化\n",
    "        vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_FEATURES)\n",
    "        # 把vgg16的平均池化层和分类层去掉, 只保留特征提取层\n",
    "        del vgg16.classifier\n",
    "        del vgg16.avgpool\n",
    "        self.features = vgg16.features\n",
    "        # 把ImageNet标准化放在模型内部，省得后期调用时再写\n",
    "        # 输入图片的像素范围是0-255，需要归一化到0-1\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    # 简单吧\n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        x = self.features(x)\n",
    "        # 展平特征图(从第1维开始，因为第0维是batch_size)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class SiameseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset: Dataset, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset (Dataset): 包含验证码数据的原始数据集。\n",
    "            transform (callable, optional): 可选的图像变换方法。\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.triplets = []  # 存储所有三元组（已裁剪但未应用变换）\n",
    "\n",
    "        # 遍历原始数据集，生成所有三元组\n",
    "        for data in dataset:\n",
    "            image = data['image']  # PIL 图像\n",
    "            objects = data['objects']\n",
    "            bboxes = objects['bbox']  # 边界框列表\n",
    "            categories = objects['categories']  # 分类标签列表\n",
    "\n",
    "            # 分离题目框和答案框\n",
    "            question_boxes = [box for box in bboxes if box[1] >= 344]  # y_min >= 344\n",
    "            answer_boxes = [box for box in bboxes if box[1] < 344]  # y_min < 344\n",
    "\n",
    "            # 构建类别映射\n",
    "            category_map = {}\n",
    "            for i, category in enumerate(categories):\n",
    "                if category not in category_map:\n",
    "                    category_map[category] = []\n",
    "                category_map[category].append(bboxes[i])\n",
    "\n",
    "            # 遍历每个题目框，生成三元组\n",
    "            for anchor_box in question_boxes:\n",
    "                anchor_category = categories[bboxes.index(anchor_box)]  # 基准样本的类别\n",
    "                positive_boxes = category_map[anchor_category]  # 激励样本（与基准样本同类别）\n",
    "                positive_boxes = [box for box in positive_boxes if box != anchor_box]\n",
    "                \n",
    "                # 如果没有正样本，跳过\n",
    "                if not positive_boxes:\n",
    "                    continue\n",
    "\n",
    "                # 负面样本：从不同类别的答案框中选择\n",
    "                negative_boxes = [\n",
    "                    box for i, box in enumerate(answer_boxes)\n",
    "                    if categories[bboxes.index(box)] != anchor_category\n",
    "                ]\n",
    "\n",
    "                # 如果没有负样本，跳过\n",
    "                if not negative_boxes:\n",
    "                    continue\n",
    "\n",
    "                # 随机选择一个正样本和一个负样本\n",
    "                positive_box = random.choice(positive_boxes)\n",
    "                negative_box = random.choice(negative_boxes)\n",
    "\n",
    "                # 裁剪图片\n",
    "                anchor_image = image.crop(anchor_box)  # 基准样本\n",
    "                positive_image = image.crop(positive_box)  # 激励样本\n",
    "                negative_image = image.crop(negative_box)  # 负面样本\n",
    "\n",
    "                # 存储三元组（已裁剪但未应用变换）\n",
    "                self.triplets.append((anchor_image, positive_image, negative_image))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        根据索引获取一组三张图片：基准样本、激励样本和负面样本。\n",
    "        \"\"\"\n",
    "        # 获取存储的三元组信息\n",
    "        anchor_image, positive_image, negative_image = self.triplets[index]\n",
    "\n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            anchor_image = self.transform(anchor_image)\n",
    "            positive_image = self.transform(positive_image)\n",
    "            negative_image = self.transform(negative_image)\n",
    "\n",
    "        return anchor_image, positive_image, negative_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "    \n",
    "\n",
    "\n",
    "    def preview(self, num_samples=5):\n",
    "        \"\"\"\n",
    "        随机预览数据集中的若干条数据。\n",
    "        \n",
    "        Args:\n",
    "            num_samples (int): 要预览的样本数量，默认为5。\n",
    "        \"\"\"\n",
    "        # 随机选择若干索引\n",
    "        indices = random.sample(range(len(self)), num_samples)\n",
    "\n",
    "        # 创建画布\n",
    "        fig, axes = plt.subplots(num_samples, 3, figsize=(10, 3 * num_samples))\n",
    "        if num_samples == 1:\n",
    "            axes = [axes]  # 单一样本时调整形状\n",
    "\n",
    "        for i, idx in enumerate(indices):\n",
    "            # 获取三元组\n",
    "            anchor, positive, negative = self[idx]\n",
    "\n",
    "            # 将 Tensor 转换为 PIL 图像（如果需要）\n",
    "            if isinstance(anchor, torch.Tensor):\n",
    "                anchor = transforms.ToPILImage()(anchor)\n",
    "                positive = transforms.ToPILImage()(positive)\n",
    "                negative = transforms.ToPILImage()(negative)\n",
    "\n",
    "            # 显示图像\n",
    "            axes[i][0].imshow(anchor)\n",
    "            axes[i][0].set_title(\"Anchor\")\n",
    "            axes[i][0].axis('off')\n",
    "\n",
    "            axes[i][1].imshow(positive)\n",
    "            axes[i][1].set_title(\"Positive\")\n",
    "            axes[i][1].axis('off')\n",
    "\n",
    "            axes[i][2].imshow(negative)\n",
    "            axes[i][2].set_title(\"Negative\")\n",
    "            axes[i][2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),  # 调整图像大小\n",
    "    transforms.ToTensor(),  # 转换为张量\n",
    "    transforms.RandomRotation(10),  # 随机旋转，最大角度为 10 度\n",
    "    transforms.RandomHorizontalFlip(), # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(), # 随机垂直翻转\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1), # 随机颜色抖动\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_dataset_train = SiameseDataset(dataset=train_dataset, transform=transform)\n",
    "siamese_dataset_test = SiameseDataset(dataset=test_dataset, transform=transform)\n",
    "print(len(siamese_dataset_train))\n",
    "print(len(siamese_dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览数据集\n",
    "siamese_dataset_train.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device=device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        \n",
    "        self.loss = nn.TripletMarginLoss(margin=2.0)\n",
    "        self.optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=0.0001,\n",
    "            weight_decay=0.5\n",
    "        )\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=20\n",
    "        )\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (a, p, n) in enumerate(self.train_loader):\n",
    "            a,p,n = a.to(self.device), p.to(self.device), n.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            a_features = self.model(a)\n",
    "            p_features = self.model(p)\n",
    "            n_features = self.model(n)\n",
    "            loss = self.loss(a_features, p_features, n_features)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            if batch_idx % 10 == 9:\n",
    "                print(f'迭代轮次: {epoch} | 批次: {batch_idx+1} | 损失: {total_loss/10:.4f}')\n",
    "                total_loss = 0.0\n",
    "                \n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for a, p, n in self.val_loader:\n",
    "                a, p, n = a.to(self.device), p.to(self.device), n.to(self.device)\n",
    "                \n",
    "                # 提取特征\n",
    "                a_features = self.model(a)\n",
    "                p_features = self.model(p)\n",
    "                n_features = self.model(n)\n",
    "                \n",
    "                # 计算损失\n",
    "                loss = self.loss(a_features, p_features, n_features)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # 使用距离判断分类正确性\n",
    "                pos_dist = torch.norm(a_features - p_features, dim=1)  # 正样本对的距离\n",
    "                neg_dist = torch.norm(a_features - n_features, dim=1)  # 负样本对的距离\n",
    "                \n",
    "                # 如果正样本距离小于负样本距离，则认为预测正确\n",
    "                correct += (pos_dist < neg_dist).sum().item()\n",
    "                total += a.size(0)\n",
    "    \n",
    "        avg_loss = val_loss / len(self.val_loader)\n",
    "        accuracy = correct / total\n",
    "        print(f'验证集损失: {avg_loss:.4f} | 验证集正确率: {accuracy:.4f}')\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "root = os.path.abspath(\"..\")\n",
    "epochs = 300\n",
    "\n",
    "train_loader = DataLoader(siamese_dataset_train, batch_size=24, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(siamese_dataset_test, batch_size=24, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# 初始化模型\n",
    "model = SiameseNet()\n",
    "# 加载参数\n",
    "# model.load_state_dict(torch.load(os.path.join(root, \"models\", \"loss0.0000_acc0.0000_chinese_click_1.pt\")))\n",
    "trainer = Trainer(model, train_loader, val_loader)\n",
    "\n",
    "# 训练循环（保持不变）\n",
    "\n",
    "\n",
    "min_loss = 1e9\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"迭代 {epoch}/{epochs}:\")\n",
    "    train_loss = trainer.train_epoch(epoch)\n",
    "    val_loss, val_acc = trainer.validate()\n",
    "    \n",
    "    trainer.scheduler.step()\n",
    "    \n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(root, \"models\", f\"loss{val_loss:4f}_acc{val_acc:4f}_chinese_click_1.pt\"))\n",
    "        print(f\"保存最优模型, 最新的损失: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导出模型为onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = SiameseNet()\n",
    "\n",
    "# 把路径更改为你保存的模型路径\n",
    "model.load_state_dict(torch.load('../models/loss0.194566_acc0.964029_chinese_click_1.pt'))\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 96, 96)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"../models/siamese.onnx\",\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'}\n",
    "    },\n",
    "    dynamo=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captcha_breaker_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
